{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from pandas.io.json import json_normalize\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense, Conv1D, MaxPool1D, AveragePooling1D, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_path, artists=[]):\n",
    "    if (os.path.isfile(json_path)):\n",
    "        print(\"json\")\n",
    "        with open(json_path) as f:\n",
    "            song_data = json.load(f)\n",
    "            return song_data['songs']\n",
    "        \n",
    "    elif (os.path.isdir(json_path)):\n",
    "        data = []\n",
    "        json_files = []\n",
    "        if (len(artists) > 0):\n",
    "            for artist in artists:\n",
    "                json_files = json_files + [json_file for json_file in os.listdir(json_path) if ((json_file.endswith('.json')) & (artist in json_file))]\n",
    "        else:\n",
    "            json_files = [json_file for json_file in os.listdir(json_path) if json_file.endswith('.json')]\n",
    "\n",
    "        for json_file in json_files:\n",
    "            path_to_json = os.path.join(json_path, json_file)\n",
    "            with open(path_to_json) as f:\n",
    "                song_data = json.load(f)\n",
    "                data = data + song_data['songs']\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "def reweight_distribution(original_distribution, temperature=0.5):\n",
    "    distribution = np.log(original_distribution) / temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    \n",
    "    return distribution / np.sum(distribution)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas)\n",
    "\n",
    "def normalize_lyric(text, lower=True):\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    text = re.sub('\\[.+\\](\\\\n)|\\[.+\\](\\(.*\\))', '', text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterts\n",
    "maxlen = 45  # extraxt sequences of n characters\n",
    "step = 1    # sample new seq every n characters\n",
    "n_grams_len = 0\n",
    "json_path = '../data/deutsch'\n",
    "artists = ['Bushido']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Songs: 100\n",
      "Corpus length: 297389\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = load_json(json_path, artists)\n",
    "df = json_normalize(data)\n",
    "lyrics = df.lyrics.map(lambda lyric: normalize_lyric(lyric))\n",
    "\n",
    "print('Number of Songs: {}'.format(len(df)))\n",
    "print('Corpus length: {}'.format(len(\"\".join(lyrics))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 292889\n",
      "Unique characters: 76\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "next_chars = []\n",
    "chars = []\n",
    "for lyric in lyrics:\n",
    "    lyric = lyric.lower()\n",
    "    if n_grams_len > 1:\n",
    "        for i in range(0, len(lyric) - maxlen - n_grams_len): # iterates by step size\n",
    "            sentences.append(lyric[i: i + maxlen]) # get maxlen amount of characters\n",
    "            next_chars.append(lyric[i + maxlen: i + maxlen + n_grams_len])\n",
    "        \n",
    "        ngrams_iter = ngrams(lyric, n_grams_len)\n",
    "        for gram in ngrams_iter:\n",
    "            chars.append(''.join(list(gram)))\n",
    "        chars = sorted(list(set(chars)))\n",
    "    else:\n",
    "        for i in range(0, len(lyric) - maxlen, step): # iterates by step size\n",
    "            sentences.append(lyric[i: i + maxlen]) # get maxlen amount of characters\n",
    "            next_chars.append(lyric[i + maxlen])\n",
    "        \n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "if n_grams_len < 1:\n",
    "    chars = sorted(list(set(''.join(lyrics)))) # list of unique characters\n",
    "\n",
    "print('Unique characters:', len(chars))\n",
    "\n",
    "char_indices = dict((char, chars.index(char)) for char in chars) # maps char with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars))) # (sentences)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1    # one hot encoding\n",
    "    y[i, char_indices[next_chars[i]]] = 1  # one hot encoding\n",
    "    \n",
    "#for i, sentence in enumerate(sentences):\n",
    "#    for t in range(0, len(sentence) - n_grams_len):\n",
    "#        char = sentence[t:t+n_grams_len]\n",
    "#        x[i, t, char_indices[char]] = 1    # one hot encoding\n",
    "#    y[i, char_indices[next_chars[i]]] = 1  # one hot encodin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, next_chars_train, next_chars_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(input_shape=(maxlen, len(chars)),\n",
    "                filters=32,\n",
    "                kernel_size=7,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=64,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "#model.add(MaxPool1D(pool_size=2))\n",
    "\n",
    "\"\"\"model.add(Conv1D(filters=64,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=32,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\"\"\"\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 45, 32)            17056     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 22, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 22, 64)            6208      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 76)                53580     \n",
      "=================================================================\n",
      "Total params: 76,844\n",
      "Trainable params: 76,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "DIR = '../outputs/charbased/CNN_Simple_CharBased_{}_E{}_BS{}_ML{}_SS{}'.format(artists[0], EPOCHS, BATCH_SIZE, maxlen, step)\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=os.path.join(DIR, 'logs'), write_images=True, write_grads=True)\n",
    "modelCheckpoint_best = ModelCheckpoint(filepath=os.path.join(DIR, \"model_best.h5\"), save_best_only=True)\n",
    "modelCheckpoint = ModelCheckpoint(filepath=os.path.join(DIR, \"model.h5\"), save_best_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/1\n",
      "219666/219666 [==============================] - 33s 148us/step - loss: 2.2044 - val_loss: 2.1261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1082501d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences_train, next_chars_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(sentences_test, next_chars_test),\n",
    "          callbacks=[tensorboard, modelCheckpoint, modelCheckpoint_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 34s 153us/step - loss: 2.2222 - val_loss: 2.1409\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 28s 126us/step - loss: 2.1755 - val_loss: 2.3182\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 28s 128us/step - loss: 2.3247 - val_loss: 2.4867\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 27s 122us/step - loss: 2.4558 - val_loss: 2.5497\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 28s 126us/step - loss: 2.5617 - val_loss: 2.6322\n",
      "wenn der benz anspringt und die reifen wieder_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 26s 117us/step - loss: 2.6395 - val_loss: 2.6505\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 2.7099 - val_loss: 2.7872\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 27s 125us/step - loss: 2.7658 - val_loss: 2.7885\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 27s 124us/step - loss: 2.8163 - val_loss: 2.7955\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 26s 118us/step - loss: 2.8467 - val_loss: 2.8093\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 25s 116us/step - loss: 2.8633 - val_loss: 2.8399\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 25s 113us/step - loss: 2.8638 - val_loss: 2.8328\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 24s 112us/step - loss: 2.8818 - val_loss: 2.9102\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 27s 122us/step - loss: 2.8974 - val_loss: 2.9079\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 27s 122us/step - loss: 2.9123 - val_loss: 2.8825\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 28s 127us/step - loss: 2.9112 - val_loss: 2.9586\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 2.9218 - val_loss: 2.8740\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 27s 123us/step - loss: 2.9254 - val_loss: 2.9010\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 28s 126us/step - loss: 2.9342 - val_loss: 3.0407\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 28s 126us/step - loss: 2.9466 - val_loss: 3.2118\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 2.9419 - val_loss: 2.9053\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 26s 120us/step - loss: 2.9308 - val_loss: 3.1205\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 26s 121us/step - loss: 2.9262 - val_loss: 3.0061\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 26s 120us/step - loss: 2.9605 - val_loss: 3.0208\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 28s 127us/step - loss: 2.9340 - val_loss: 2.9527\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 28s 128us/step - loss: 2.9362 - val_loss: 3.1461\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 28s 126us/step - loss: 2.9547 - val_loss: 3.0842\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 26s 120us/step - loss: 2.9920 - val_loss: 2.9751\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 29s 134us/step - loss: 3.0110 - val_loss: 2.9917\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 30s 134us/step - loss: 2.9682 - val_loss: 3.1116\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 27s 123us/step - loss: 2.9982 - val_loss: 3.0727\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 27s 124us/step - loss: 2.9957 - val_loss: 2.9375\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 27s 122us/step - loss: 2.9636 - val_loss: 3.0332\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 27s 121us/step - loss: 2.9747 - val_loss: 3.1427\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 27s 123us/step - loss: 3.0358 - val_loss: 3.2827\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 27s 125us/step - loss: 3.0074 - val_loss: 3.0908\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 27s 122us/step - loss: 3.0360 - val_loss: 2.9930\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 27s 122us/step - loss: 3.0322 - val_loss: 3.1899\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 28s 125us/step - loss: 3.0207 - val_loss: 3.0117\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 27s 123us/step - loss: 3.0303 - val_loss: 3.0811\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 26s 119us/step - loss: 3.0506 - val_loss: 3.1999\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 3.0090 - val_loss: 2.9626\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 3.0170 - val_loss: 2.9119\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 26s 118us/step - loss: 3.0205 - val_loss: 3.0998\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 3.0080 - val_loss: 3.1102\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 26s 117us/step - loss: 3.0116 - val_loss: 3.1942\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 25s 116us/step - loss: 3.0300 - val_loss: 3.0441\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 26s 117us/step - loss: 3.0193 - val_loss: 2.9452\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 25s 114us/step - loss: 2.9973 - val_loss: 2.9429\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 26s 116us/step - loss: 3.0203 - val_loss: 3.0049\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219666/219666 [==============================] - 27s 122us/step - loss: 3.0028 - val_loss: 3.1650\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 111us/step - loss: 3.0174 - val_loss: 2.9717\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 25s 114us/step - loss: 3.0459 - val_loss: 3.1629\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 25s 113us/step - loss: 2.9902 - val_loss: 2.9805\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 3.0130 - val_loss: 3.0059\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 25s 113us/step - loss: 3.0136 - val_loss: 2.9433\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 23s 104us/step - loss: 3.0637 - val_loss: 3.0702\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0292 - val_loss: 2.9987\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0123 - val_loss: 2.9375\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 24s 108us/step - loss: 3.0557 - val_loss: 3.3278\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 29s 131us/step - loss: 3.0384 - val_loss: 3.0621\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 23s 104us/step - loss: 3.0156 - val_loss: 3.1056\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 23s 107us/step - loss: 3.0178 - val_loss: 2.9818\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 2.9846 - val_loss: 2.9861\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 2.9843 - val_loss: 2.9478\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 26s 117us/step - loss: 3.0183 - val_loss: 2.9910\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 111us/step - loss: 2.9912 - val_loss: 2.9550\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 2.9857 - val_loss: 2.9331\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 2.9999 - val_loss: 3.0552\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 2.9825 - val_loss: 2.9379\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 24s 107us/step - loss: 3.0300 - val_loss: 2.9775\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 3.0159 - val_loss: 2.9707\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 25s 114us/step - loss: 3.0356 - val_loss: 2.9963\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 25s 113us/step - loss: 3.0538 - val_loss: 3.0076\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 3.0183 - val_loss: 2.9338\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 3.0035 - val_loss: 2.9324\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 23s 103us/step - loss: 2.9938 - val_loss: 2.9812\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 24s 108us/step - loss: 3.0467 - val_loss: 2.9432\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 3.0198 - val_loss: 3.1532\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 27s 121us/step - loss: 3.0164 - val_loss: 2.9491\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 24s 107us/step - loss: 3.0284 - val_loss: 3.0095\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 23s 104us/step - loss: 3.0212 - val_loss: 3.1485\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0247 - val_loss: 3.0474\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 2.9842 - val_loss: 2.9449\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 24s 108us/step - loss: 2.9906 - val_loss: 2.9897\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 3.0073 - val_loss: 3.0155\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 22s 102us/step - loss: 3.0353 - val_loss: 3.0190\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0063 - val_loss: 3.0005\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 2.9936 - val_loss: 2.9226\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 25s 113us/step - loss: 2.9843 - val_loss: 3.0275\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 24s 111us/step - loss: 2.9673 - val_loss: 3.2071\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 108us/step - loss: 2.9607 - val_loss: 2.9152\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 22s 101us/step - loss: 2.9755 - val_loss: 3.0254\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 2.9795 - val_loss: 2.9698\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 25s 112us/step - loss: 2.9872 - val_loss: 3.1458\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 24s 111us/step - loss: 2.9768 - val_loss: 3.0013\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 108us/step - loss: 2.9912 - val_loss: 2.9468\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 3.0258 - val_loss: 2.9541\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219666/219666 [==============================] - 26s 117us/step - loss: 2.9772 - val_loss: 2.9692\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 3.0031 - val_loss: 2.9429\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 2.9823 - val_loss: 3.3149\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 110us/step - loss: 2.9908 - val_loss: 2.9337\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 29s 132us/step - loss: 2.9897 - val_loss: 2.9609\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 24s 111us/step - loss: 2.9993 - val_loss: 2.9446\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 25s 112us/step - loss: 2.9652 - val_loss: 2.9306\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 25s 113us/step - loss: 2.9634 - val_loss: 3.2097\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 2.9873 - val_loss: 2.9445\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 29s 131us/step - loss: 2.9805 - val_loss: 2.9918\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 24s 111us/step - loss: 2.9860 - val_loss: 3.0638\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 24s 111us/step - loss: 2.9798 - val_loss: 2.9738\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 23s 107us/step - loss: 2.9877 - val_loss: 2.9685\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 2.9932 - val_loss: 2.9651\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 23s 102us/step - loss: 3.0153 - val_loss: 2.9667\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0123 - val_loss: 2.9815\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 3.0022 - val_loss: 3.0312\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 23s 105us/step - loss: 2.9960 - val_loss: 2.9647\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 108us/step - loss: 3.0240 - val_loss: 3.0456\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 24s 108us/step - loss: 2.9994 - val_loss: 2.9798\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0070 - val_loss: 2.9780\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0052 - val_loss: 3.0538\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0185 - val_loss: 3.0486\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 107us/step - loss: 3.1074 - val_loss: 3.1547\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 24s 109us/step - loss: 3.1037 - val_loss: 3.0624\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 31s 142us/step - loss: 3.0791 - val_loss: 3.0859\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 32s 146us/step - loss: 3.0975 - val_loss: 3.1194\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 33s 152us/step - loss: 3.0847 - val_loss: 3.0770\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 31s 139us/step - loss: 3.0871 - val_loss: 3.1044\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 29s 130us/step - loss: 3.0774 - val_loss: 3.0746\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 32s 147us/step - loss: 3.0741 - val_loss: 3.0652\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 31s 143us/step - loss: 3.0742 - val_loss: 3.0550\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0694 - val_loss: 3.0831\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 110us/step - loss: 3.0763 - val_loss: 3.0982\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 26s 119us/step - loss: 3.0663 - val_loss: 3.0714\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 25s 114us/step - loss: 3.0762 - val_loss: 3.0858\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 26s 116us/step - loss: 3.0882 - val_loss: 3.0803\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 25s 116us/step - loss: 3.0697 - val_loss: 3.0617\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 24s 110us/step - loss: 3.0709 - val_loss: 3.0561\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 23s 107us/step - loss: 3.0765 - val_loss: 3.0539\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 25s 112us/step - loss: 3.0645 - val_loss: 3.0674\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 25s 114us/step - loss: 3.0514 - val_loss: 3.0424\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "Train on 219666 samples, validate on 73223 samples\n",
      "Epoch 1/5\n",
      "219666/219666 [==============================] - 26s 117us/step - loss: 3.0591 - val_loss: 3.0560\n",
      "Epoch 2/5\n",
      "219666/219666 [==============================] - 25s 115us/step - loss: 3.0579 - val_loss: 3.0582\n",
      "Epoch 3/5\n",
      "219666/219666 [==============================] - 26s 118us/step - loss: 3.0454 - val_loss: 3.0446\n",
      "Epoch 4/5\n",
      "219666/219666 [==============================] - 25s 113us/step - loss: 3.0504 - val_loss: 3.0692\n",
      "Epoch 5/5\n",
      "219666/219666 [==============================] - 23s 106us/step - loss: 3.0718 - val_loss: 3.0638\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n",
      "wenn der benz anspringt und die reifen wieder_\n"
     ]
    }
   ],
   "source": [
    "for it in range(1, 30):\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 64\n",
    "    GEN_CHAR_LEN = 2973\n",
    "\n",
    "    DIR = '../outputs/charbased/CNN_Simple_CharBased_{}_E{}_BS{}_ML{}_SS{}'.format(artists[0], EPOCHS*it, BATCH_SIZE, maxlen, step)\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=os.path.join(DIR, 'logs'), write_images=True, write_grads=True)\n",
    "    modelCheckpoint_best = ModelCheckpoint(filepath=os.path.join(DIR, \"model_best.h5\"), save_best_only=True)\n",
    "    modelCheckpoint = ModelCheckpoint(filepath=os.path.join(DIR, \"model.h5\"), save_best_only=False)\n",
    "        \n",
    "    model.fit(sentences_train, next_chars_train, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(sentences_test, next_chars_test),\n",
    "          callbacks=[tensorboard, modelCheckpoint, modelCheckpoint_best])\n",
    "    \n",
    "    temperatures = [0.2, 0.4, 0.5, 0.6, 0.8, 1.]\n",
    "    for temperature in temperatures:\n",
    "        generated_text_temp = \"wenn der benz anspringt und die reifen wieder\"\n",
    "        generated_text = generated_text_temp\n",
    "        print(generated_text + '_')\n",
    "        #print('\\n___________________\\n')\n",
    "        for i in range(GEN_CHAR_LEN):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "\n",
    "            for t, char in enumerate(generated_text_temp):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "            generated_text_temp += next_char\n",
    "            generated_text += next_char\n",
    "            generated_text_temp = generated_text_temp[1:]\n",
    "            #sys.stdout.write(next_char)\n",
    "        \n",
    "        with open(os.path.join(DIR, '{}_temp{}_text.txt'.format(artists[0], temperature)), 'w+') as text_file:\n",
    "            text_file.write(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shidos\n",
      "ich kam aus dem ghetto auf die leinwan\n",
      "n ich wie kan und die denn in die kicken  zum ferdun mich hericht junge sein \n",
      "dick senn ist denn sos, ich haben die mir was wir dich bin hier rinzast wein ich deine seine nin die fickt fass ip, sein tlog perbe mein so auf\n",
      "die schah ainter kinden mein rib ein clip gesten es die mein und rasen\n",
      "wie mergenicht ich beiwe und der dich auf die keine deinen fannst du die denn die e"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ins jeden mir in die dich ist und der verim sind mir in vorser anden nicht\n",
      "der du ich das yaft\n",
      "ich wir dich dich sein nicht die big wie bar \n",
      "ich bin manne geinmene bann manne tifst du jeld blare einen blann dein ein zu wenn ihr schann wir wie big in und ich ich mir schund ich woll die dich die des cizzum habt wit wes nicht denn fann auf die für dich sind heur astnicht wir eine inder mir deinen eint mir richt mir die auf der beifen jeld die bin so pein, gannst du nenndas nicht die zu mich ist erafwec gingzwirne anden was ist dich nicht die gonnk f win dar ticht sobe will kann ich die ist du willst ern in schaln soingann die denn denn jeld sind den die woin die verwicht einen  dise gein boir\n",
      "ich bin sond ich bin mich enden rauf den einginnter -wein der wie ind und schusste kalod ein mir auf der dich die lann war was war genden glar ist du dannen weine zu siehs ainst du schace weine sind wird mitser zinds wir mir wer ich sich sein are songst du nicht die dich will du nicht die fim-tre schussten jetzt weitern für die die jaffurim anngackkers nicht die frick in fehr mir geht die kamf viele geigim bos denn die wo"
     ]
    }
   ],
   "source": [
    "temperature = 0.5\n",
    "\n",
    "#start_index = random.randint(0, len(lyrics) - maxlen - 1)\n",
    "#generated_text = lyrics[start_index: start_index + maxlen]\n",
    "random.seed(3004)\n",
    "lyrics_index = random.randint(0, len(lyrics))\n",
    "chosen_lyric = lyrics[lyrics_index]\n",
    "start_index = random.randint(0, len(chosen_lyric) - maxlen - 1)\n",
    "generated_text_temp = chosen_lyric[start_index: start_index + maxlen]\n",
    "generated_text = generated_text_temp\n",
    "print(generated_text)\n",
    "#print('\\n___________________\\n')\n",
    "for i in range(1500):\n",
    "    sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            \n",
    "    for t, char in enumerate(generated_text_temp):\n",
    "        sampled[0, t, char_indices[char]] = 1.\n",
    "                      \n",
    "    preds = model.predict(sampled, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = chars[next_index]\n",
    "    generated_text_temp += next_char\n",
    "    generated_text += next_char\n",
    "    generated_text_temp = generated_text_temp[1:]\n",
    "    sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = \"Bushido_60epochs_30maxlen_0ngrams\"\n",
    "with open('./increase_epochs/texts/' + file_name + '.txt', 'w') as text_file:\n",
    "    text_file.write(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
