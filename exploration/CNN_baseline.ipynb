{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense, MaxPool1D, Conv1D, AveragePooling1D, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_path, artists=[]):\n",
    "    if (os.path.isfile(json_path)):\n",
    "        print(\"json\")\n",
    "        with open(json_path) as f:\n",
    "            song_data = json.load(f)\n",
    "            return song_data['songs']\n",
    "        \n",
    "    elif (os.path.isdir(json_path)):\n",
    "        data = []\n",
    "        json_files = []\n",
    "        if (len(artists) > 0):\n",
    "            for artist in artists:\n",
    "                json_files = json_files + [json_file for json_file in os.listdir(json_path) if ((json_file.endswith('.json')) & (artist in json_file))]\n",
    "        else:\n",
    "            json_files = [json_file for json_file in os.listdir(json_path) if json_file.endswith('.json')]\n",
    "\n",
    "        for json_file in json_files:\n",
    "            path_to_json = os.path.join(json_path, json_file)\n",
    "            with open(path_to_json) as f:\n",
    "                song_data = json.load(f)\n",
    "                data = data + song_data['songs']\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "def reweight_distribution(original_distribution, temperature=0.5):\n",
    "    distribution = np.log(original_distribution) / temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    \n",
    "    return distribution / np.sum(distribution)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterts\n",
    "maxlen = 60  # extraxt sequences of n characters\n",
    "step = 3     # sample new seq every n characters\n",
    "n_grams = 0\n",
    "json_path = '../data/deutsch'\n",
    "artists = ['Bushido']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Songs: 100\n",
      "Corpus length: 303654\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = load_json(json_path, artists)\n",
    "df = json_normalize(data)\n",
    "lyrics = df.lyrics.map(lambda lyric: lyric.lower())\n",
    "\n",
    "print('Number of Songs: {}'.format(len(df)))\n",
    "print('Corpus length: {}'.format(len(\"\".join(lyrics))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 99246\n",
      "Unique characters: 78\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "next_chars = []\n",
    "for lyric in lyrics:\n",
    "    lyric = lyric.lower()\n",
    "    for i in range(0, len(lyric) - maxlen, step): # iterates by step size\n",
    "        sentences.append(lyric[i: i + maxlen]) # get maxlen amount of charachters\n",
    "        next_chars.append(lyric[i + maxlen])\n",
    "    \n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(\"\".join(lyrics).lower()))) # list of unique characters\n",
    "print('Unique characters:', len(chars))\n",
    "\n",
    "char_indices = dict((char, chars.index(char)) for char in chars) # maps char with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars))) # (sentences)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1    # one hot encoding\n",
    "    y[i, char_indices[next_chars[i]]] = 1  # one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(input_shape=(maxlen, len(chars)),\n",
    "                filters=10,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=20,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "#model.add(MaxPool1D(pool_size=2))\n",
    "\n",
    "\"\"\"model.add(Conv1D(filters=64,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=32,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                strides=1))\"\"\"\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 60, 10)            2350      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 30, 20)            620       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 15, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 78)                23478     \n",
      "=================================================================\n",
      "Total params: 26,448\n",
      "Trainable params: 26,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "99246/99246 [==============================] - 13s 127us/step - loss: 2.5407\n",
      "Epoch 2/60\n",
      "99246/99246 [==============================] - 9s 87us/step - loss: 2.2013\n",
      "Epoch 3/60\n",
      "99246/99246 [==============================] - 9s 90us/step - loss: 2.1423\n",
      "Epoch 4/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.1165\n",
      "Epoch 5/60\n",
      "99246/99246 [==============================] - 9s 88us/step - loss: 2.1011\n",
      "Epoch 6/60\n",
      "99246/99246 [==============================] - 9s 87us/step - loss: 2.0922\n",
      "Epoch 7/60\n",
      "99246/99246 [==============================] - 9s 94us/step - loss: 2.0898\n",
      "Epoch 8/60\n",
      "99246/99246 [==============================] - 9s 91us/step - loss: 2.0870\n",
      "Epoch 9/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.0869\n",
      "Epoch 10/60\n",
      "99246/99246 [==============================] - 9s 93us/step - loss: 2.0884\n",
      "Epoch 11/60\n",
      "99246/99246 [==============================] - 9s 90us/step - loss: 2.0903\n",
      "Epoch 12/60\n",
      "99246/99246 [==============================] - 9s 88us/step - loss: 2.0902\n",
      "Epoch 13/60\n",
      "99246/99246 [==============================] - 9s 89us/step - loss: 2.0936\n",
      "Epoch 14/60\n",
      "99246/99246 [==============================] - 9s 88us/step - loss: 2.0952\n",
      "Epoch 15/60\n",
      "99246/99246 [==============================] - 9s 88us/step - loss: 2.0966\n",
      "Epoch 16/60\n",
      "99246/99246 [==============================] - 9s 88us/step - loss: 2.0980\n",
      "Epoch 17/60\n",
      "99246/99246 [==============================] - 9s 92us/step - loss: 2.0965\n",
      "Epoch 18/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.0989\n",
      "Epoch 19/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1039\n",
      "Epoch 20/60\n",
      "99246/99246 [==============================] - 9s 87us/step - loss: 2.1067\n",
      "Epoch 21/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1083\n",
      "Epoch 22/60\n",
      "99246/99246 [==============================] - 9s 88us/step - loss: 2.1096\n",
      "Epoch 23/60\n",
      "99246/99246 [==============================] - 8s 86us/step - loss: 2.1071\n",
      "Epoch 24/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.1109\n",
      "Epoch 25/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.1150\n",
      "Epoch 26/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1171\n",
      "Epoch 27/60\n",
      "99246/99246 [==============================] - 9s 87us/step - loss: 2.1177\n",
      "Epoch 28/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1208\n",
      "Epoch 29/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1241\n",
      "Epoch 30/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1256\n",
      "Epoch 31/60\n",
      "99246/99246 [==============================] - 9s 87us/step - loss: 2.1336\n",
      "Epoch 32/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1324\n",
      "Epoch 33/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1346\n",
      "Epoch 34/60\n",
      "99246/99246 [==============================] - 8s 86us/step - loss: 2.1387\n",
      "Epoch 35/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.1423\n",
      "Epoch 36/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.1450\n",
      "Epoch 37/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1484\n",
      "Epoch 38/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.1513\n",
      "Epoch 39/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1519\n",
      "Epoch 40/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.1580\n",
      "Epoch 41/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.1620\n",
      "Epoch 42/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1652\n",
      "Epoch 43/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1683\n",
      "Epoch 44/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1746\n",
      "Epoch 45/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.1789\n",
      "Epoch 46/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.1800\n",
      "Epoch 47/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1863\n",
      "Epoch 48/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.1922\n",
      "Epoch 49/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.2015\n",
      "Epoch 50/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.1991\n",
      "Epoch 51/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.2049\n",
      "Epoch 52/60\n",
      "99246/99246 [==============================] - 9s 86us/step - loss: 2.2098\n",
      "Epoch 53/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.2113\n",
      "Epoch 54/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.2126\n",
      "Epoch 55/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.2169\n",
      "Epoch 56/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.2246\n",
      "Epoch 57/60\n",
      "99246/99246 [==============================] - 9s 87us/step - loss: 2.2272\n",
      "Epoch 58/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.2292\n",
      "Epoch 59/60\n",
      "99246/99246 [==============================] - 8s 85us/step - loss: 2.2359\n",
      "Epoch 60/60\n",
      "99246/99246 [==============================] - 8s 84us/step - loss: 2.2430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be700f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 60\n",
    "model.fit(x, y, batch_size=128, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = artists[0]\n",
    "file_name = '{}_{}epochs_{}maxlen_{}ngrams_CNN2'.format(artist, epochs, maxlen, n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bushido_60epochs_60maxlen_0ngrams_CNN2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_{}.h5'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e fickst\n",
      "ich hab diese welt geschaffen für mich\n",
      "wie das geht\n",
      "t zund\n",
      "stase manse ich all ich danden\n",
      " deuten mie dichen sten, weiter schund\n",
      "michen delr nach sgonci wierens der hand du del all deine mein anden traes du sakuendtd bind som-s wie waine deine dein ger dich dim dein hier fick jederau "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wang sesche dann sein, hals der der dicht schite seidt der nanemen dein dand hastoel deine mit hanf dicht dein nie dinden wahr du dits wie an dehren meine den dit dahr deun dein wai in deine wein seh ich dichen dein delrel banne deine dehr dein be hilr deinenms ich dahl ein dain gantenn deine nanmener dein schrebenla dein kannten dicht manden in du daine dit dest deinem inden in deuner wein\n",
      "es dindt deine all all meinen stnapcs dand die ist dichenncht deinener be\n",
      "rore deb ne aue nach del die dein ich be mie dimr wie dicher\n",
      "latd scheist destseiben mir dein diten\n",
      " eunase delerz dinden kein ich ihren dinden wein, die al\n",
      "die mein missennstdits seit ihn mehren ball wie mehr ich dus dichent aumenert alt ich mand wai eine wein ge eins hanc jetzt nicher dichen\n",
      "ranrerlich was ich gin mein nach dit du dahr sigs ab weid ich binnensenn hiesensteich dein verm dich del bindt neckende ditänst du dand seine art dandas del der del scho ich wie dein reih(du ich wons waisi beh ist dich dand gean mans dein ich nind kund dest, hast in kach hel du deiner michen deine dicht, sind anden del deine deine gacw soi ge gand bind den dind sind aus dicht geaf sind verstreldt dass wie antens du sirl\n",
      "ich wer es dest dind wie dicht nas und so derensendtenrenfind deiner deine wai d"
     ]
    }
   ],
   "source": [
    "temperature = 0.5\n",
    "\n",
    "#start_index = random.randint(0, len(lyrics) - maxlen - 1)\n",
    "#generated_text = lyrics[start_index: start_index + maxlen]\n",
    "lyrics_index = random.randint(0, len(lyrics))\n",
    "chosen_lyric = lyrics[lyrics_index]\n",
    "start_index = random.randint(0, len(chosen_lyric) - maxlen - 1)\n",
    "generated_text_temp = chosen_lyric[start_index: start_index + maxlen]\n",
    "generated_text = generated_text_temp\n",
    "print(generated_text)\n",
    "#print('\\n___________________\\n')\n",
    "for i in range(1500):\n",
    "    sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            \n",
    "    for t, char in enumerate(generated_text_temp):\n",
    "        sampled[0, t, char_indices[char]] = 1.\n",
    "                      \n",
    "    preds = model.predict(sampled, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = chars[next_index]\n",
    "    generated_text_temp += next_char\n",
    "    generated_text += next_char\n",
    "    generated_text_temp = generated_text_temp[1:]\n",
    "    sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name + '.txt', 'w') as text_file:\n",
    "    text_file.write(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
